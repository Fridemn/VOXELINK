"""
app/config/default.py
é»˜è®¤é…ç½®å†…å®¹ã€‚
- å­˜å‚¨å„ç±»é»˜è®¤é…ç½®å­—å…¸ã€‚
- ä½¿ç”¨ TypeVar é‡æ„ç¯å¢ƒå˜é‡è¯»å–ï¼Œæ”¯æŒç±»å‹è½¬æ¢å’Œå‚æ•°åŒ–é…ç½®ã€‚
"""

import os
import sys
from typing import Optional, TypeVar, Type
from dotenv import load_dotenv
from .constant import *

load_dotenv(override=True)

_T = TypeVar("_T")


def get_env(key: str, type_: Type[_T], default: Optional[_T] = None) -> _T:
    """è·å–æŒ‡å®šçš„ç¯å¢ƒå˜é‡ï¼Œå¹¶è‡ªåŠ¨è½¬æ¢ä¸ºæŒ‡å®šçš„ç±»å‹ã€‚è‹¥ default ä¸º Noneï¼Œåˆ™è¡¨ç¤ºè¯¥ç¯å¢ƒå˜é‡ä¸ºå¿…éœ€é¡¹"""
    value = os.getenv(key)

    if value is None:
        if default is None:
            print(f"âŒ Error: Required env variable '{key}' (type={type_}) not found.")
            print(f"ğŸ‘‰ Please setup '{key}' in your '.env' file.")
            sys.exit(1)
        return default

    if type_ == str:
        result = value
    elif type_ == int:
        result = int(value)
    elif type_ == float:
        result = float(value)
    elif type_ == bool:
        result = value.lower() in ("true", "1", "yes", "on")
    elif type_ == list:
        result = value.split(",") if value else []
    else:
        raise TypeError(f"Unsupported conversion type: {type_}")

    assert isinstance(result, type_)
    return result


# é…ç½®å­—å…¸
DEFAULT_CONFIG = {
    "openai": {
        "api_key": get_env("OPENAI_API_KEY", str, "sk-default-key"),
        "base_url": get_env("OPENAI_BASE_URL", str, "https://api.openai.com/v1"),
    },
    "anthropic": {
        "api_key": get_env("ANTHROPIC_API_KEY", str, "sk-ant-default-key"),
    },
    "custom_endpoint": {
        "api_key": get_env("CUSTOM_ENDPOINT_API_KEY", str, "default-custom-key"),
    },
    "stt": {
        "active_service": get_env("STT_ACTIVE_SERVICE", str, "openai"),
        "openai_model": get_env("STT_OPENAI_MODEL", str, "whisper-1"),
    },
    "tts": {
        "active_service": get_env("TTS_ACTIVE_SERVICE", str, "edge"),
        "edge_voice": get_env("TTS_EDGE_VOICE", str, "zh-CN-XiaoxiaoNeural"),
    },
    "llm": {
        "default_model": get_env("LLM_DEFAULT_MODEL", str, "gpt-3.5-turbo"),
        "openai_models": get_env("LLM_OPENAI_MODELS", list, ["gpt-3.5-turbo", "gpt-4"]),
        "anthropic_models": get_env("LLM_ANTHROPIC_MODELS", list, ["claude-3-7-sonnet"]),
        "ollama_base_url": get_env("LLM_OLLAMA_BASE_URL", str, "http://localhost:11434"),
        "ollama_models": get_env("LLM_OLLAMA_MODELS", list, ["llama2"]),
        "custom_endpoint_base_url": get_env("LLM_CUSTOM_ENDPOINT_BASE_URL", str, "http://your-custom-endpoint"),
        "custom_endpoint_models": get_env("LLM_CUSTOM_ENDPOINT_MODELS", list, ["custom-model-1"]),
    },
    "database": {
        "engine": get_env("DB_ENGINE", str, "sqlite"),
        "use_tz": get_env("DB_USE_TZ", bool, True),
        "time_zone": get_env("DB_TIME_ZONE", str, "Asia/Shanghai"),
    },
    "jwt": {
        "secret_key": get_env("JWT_SECRET_KEY", str, "your-secret-key-here"),
        "algorithm": get_env("JWT_ALGORITHM", str, "HS256"),
        "access_token_expire_minutes": get_env("JWT_ACCESS_TOKEN_EXPIRE_MINUTES", int, 30),
    },
}

# TTSæœåŠ¡é…ç½®
DEFAULT_CONFIG["tts_config"] = {
    "base_url": os.getenv("TTS_BASE_URL", "http://localhost:9880"),  # TTSæœåŠ¡çš„åŸºç¡€URL
    "default_character": "march7",
    "default_mood": "normal",
}
