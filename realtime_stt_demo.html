<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VOXELINK 实时语音识别演示 - 重构版</title>
    <style>
        body {
            font-family: 'Microsoft YaHei', Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        h1 {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }
        .status-bar {
            margin: 20px 0;
            padding: 10px;
            background-color: #ecf0f1;
            border-radius: 4px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        .status-indicator {
            display: inline-block;
            width: 15px;
            height: 15px;
            border-radius: 50%;
            margin-right: 8px;
            background-color: #e74c3c;
        }
        .status-indicator.connected {
            background-color: #2ecc71;
        }
        .settings {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 4px;
            margin: 20px 0;
        }
        .settings-row {
            display: flex;
            justify-content: space-between;
            margin: 10px 0;
            flex-wrap: wrap;
        }
        .settings-item {
            display: flex;
            align-items: center;
            gap: 8px;
            margin: 5px 0;
        }
        .controls {
            margin: 20px 0;
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
        }
        button {
            padding: 10px 15px;
            border: none;
            border-radius: 4px;
            background-color: #3498db;
            color: white;
            cursor: pointer;
            font-size: 16px;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #2980b9;
        }
        button:disabled {
            background-color: #95a5a6;
            cursor: not-allowed;
        }
        button.stop {
            background-color: #e74c3c;
        }
        button.stop:hover {
            background-color: #c0392b;
        }
        .voice-activity {
            display: flex;
            align-items: center;
            margin: 15px 0;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 4px;
        }
        .voice-indicator {
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background-color: #bdc3c7;
            margin-right: 10px;
            transition: background-color 0.3s;
        }
        .voice-indicator.active {
            background-color: #2ecc71;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        .recording-status {
            margin: 10px 0;
            padding: 8px;
            background-color: #e8f4fd;
            border-radius: 4px;
            font-weight: bold;
            color: #2c3e50;
        }
        .transcript-container {
            margin-top: 20px;
            border: 1px solid #ddd;
            border-radius: 4px;
            padding: 15px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            background-color: #fff;
        }
        .transcript {
            white-space: pre-wrap;
            line-height: 1.5;
        }        .message {
            margin-bottom: 10px;
            padding: 10px;
            border-radius: 4px;
        }
        .user-message {
            background-color: #e8f4fd;
            border-left: 3px solid #3498db;
        }
        .vad-debug-panel {
            margin-top: 20px;
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 4px;
            border: 1px solid #dee2e6;
        }
        .vad-debug-panel h3 {
            margin-top: 0;
            color: #2c3e50;
            font-size: 16px;
        }
        .vad-meter {
            margin: 10px 0;
            height: 20px;
            background-color: #ecf0f1;
            border-radius: 10px;
            overflow: hidden;
            position: relative;
        }
        .vad-meter-fill {
            height: 100%;
            background-color: #3498db;
            transition: width 0.2s ease-out;
            position: absolute;
            left: 0;
            top: 0;
        }
        .vad-meter-threshold {
            height: 100%;
            width: 2px;
            background-color: #e74c3c;
            position: absolute;
            transition: left 0.2s ease-out;
        }
        .vad-stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 10px;
            margin-top: 10px;
        }
        .vad-stat-item {
            background-color: white;
            padding: 8px;
            border-radius: 4px;
            border: 1px solid #dee2e6;
        }
        .vad-stat-label {
            font-size: 12px;
            color: #6c757d;
            margin-bottom: 4px;
        }
        .vad-stat-value {
            font-size: 14px;
            font-weight: bold;
            color: #2c3e50;
        }
        .system-message {
            background-color: #f8f9fa;
            border-left: 3px solid #95a5a6;
            font-style: italic;
            color: #7f8c8d;
        }
        .partial-result {
            background-color: #fff3cd;
            border-left: 3px solid #ffc107;
            font-style: italic;
        }
        .error-message {
            background-color: #f8d7da;
            border-left: 3px solid #dc3545;
            color: #721c24;
        }
        .llm-response {
            background-color: #d1ecf1;
            border-left: 3px solid #0c5460;
            font-style: normal;
            padding: 10px;
            margin: 5px 0;
            border-radius: 4px;
        }
        .llm-response-header {
            font-weight: bold;
            color: #0c5460;
            margin-bottom: 5px;
        }
        .info-text {
            background-color: #d1ecf1;
            border: 1px solid #bee5eb;
            padding: 15px;
            border-radius: 4px;
            color: #0c5460;
        }
        .info-text p {
            margin: 8px 0;
        }
        input[type="text"] {
            padding: 8px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 14px;
        }
        input[type="checkbox"] {
            margin-right: 5px;
        }
        label {
            font-weight: normal;
            margin: 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🎤 VOXELINK 实时语音识别演示</h1>
          <div class="status-bar">            <div>
                <span class="status-indicator" id="connection-status"></span>
                <span id="status-text">未连接</span>
            </div>
            <div>
                <span id="server-info">服务器: 未连接</span> | 
                <span id="userInfo">用户: 未识别</span> | 
                <span id="audio-format">音频格式: WAV</span>
            </div>
        </div>
        
        <div class="settings">
            <h3>设置</h3>
            <div class="settings-row">
                <div class="settings-item">
                    <input type="checkbox" id="check-voiceprint" checked>
                    <label for="check-voiceprint">启用声纹检查</label>
                </div>
                <div class="settings-item">
                    <input type="checkbox" id="only-register-user">
                    <label for="only-register-user">仅识别已注册用户</label>
                </div>
                <div class="settings-item">
                    <input type="checkbox" id="identify-unregistered" checked>
                    <label for="identify-unregistered">识别未注册用户</label>
                </div>
            </div>
            <div class="settings-row">
                <div class="settings-item">
                    <label for="server-url">服务器地址:</label>
                    <input type="text" id="server-url" value="ws://localhost:8080/stt/ws" style="width: 250px;">
                </div>
                <div class="settings-item">
                    <label for="api-key">API密钥:</label>
                    <input type="text" id="api-key" placeholder="可选" style="width: 250px;">
                </div>
            </div>
            <div class="settings-row">
                <div class="settings-item">
                    <label for="user-token">用户Token:</label>
                    <input type="text" id="user-token" placeholder="用于LLM调用的用户Token" style="width: 400px;">
                </div>
            </div>
            <div class="settings-row">
                <div class="settings-item">
                    <label for="llm-api-url">LLM API地址:</label>
                    <input type="text" id="llm-api-url" placeholder="例如: http://localhost:8080/llm/chat" style="width: 400px;">
                </div>
            </div>
        </div>
        
        <div class="controls">
            <button id="connect-btn">连接服务器</button>
            <button id="disconnect-btn" disabled>断开连接</button>
            <button id="start-btn" disabled>开始录音</button>
            <button id="stop-btn" class="stop" disabled>停止录音</button>
            <button id="clear-btn">清空记录</button>
        </div>
        
        <div class="voice-activity">
            <div class="voice-indicator" id="voice-indicator"></div>
            <span id="voice-status">未检测到语音</span>
        </div>
          <div class="recording-status">
            <span id="recording-status">未开始录音</span>
        </div>
        
        <!-- VAD调试面板 -->
        <div class="vad-debug-panel">
            <h3>VAD 实时调试信息</h3>
            <div class="vad-meter">
                <div class="vad-meter-fill" id="vad-meter-fill"></div>
                <div class="vad-meter-threshold" id="vad-meter-threshold"></div>
            </div>
            <div class="vad-stats">
                <div class="vad-stat-item">
                    <div class="vad-stat-label">当前RMS</div>
                    <div class="vad-stat-value" id="vad-rms">0.000</div>
                </div>
                <div class="vad-stat-item">
                    <div class="vad-stat-label">阈值</div>
                    <div class="vad-stat-value" id="vad-threshold">0.025</div>
                </div>
                <div class="vad-stat-item">
                    <div class="vad-stat-label">VAD置信度</div>
                    <div class="vad-stat-value" id="vad-confidence">0.00</div>
                </div>
                <div class="vad-stat-item">
                    <div class="vad-stat-label">语音状态</div>
                    <div class="vad-stat-value" id="vad-status">静音</div>
                </div>
                <div class="vad-stat-item">
                    <div class="vad-stat-label">音频时长</div>
                    <div class="vad-stat-value" id="audio-duration">0.00s</div>
                </div>
            </div>
        </div>
        
        <div class="transcript-container">
            <div class="transcript" id="transcript"></div>
        </div>
        
        <div class="info-text" style="margin-top: 15px;">
            <p><strong>使用说明:</strong></p>
            <p>1. <strong>配置LLM服务</strong>: 在"LLM API地址"输入框中输入您的LLM服务API地址</p>
            <p>2. <strong>输入用户Token</strong>: 在"用户Token"输入框中输入您的LLM API Token</p>
            <p>3. 点击"连接服务器"连接到语音识别服务</p>
            <p>4. 点击"开始录音"开始实时语音识别</p>
            <p>5. 对着麦克风说话，系统会实时显示识别结果</p>
            <p>6. <strong>自动LLM调用</strong>: 如果配置了Token和API地址，识别到的文本会自动发送给LLM并显示响应</p>
            <p>7. 绿色指示灯亮起表示正在检测到语音</p>
            <p><strong>注意:</strong> 
               <br>• 请确保浏览器支持WebSocket和麦克风访问权限
               <br>• LLM功能需要配置正确的API地址和Token
               <br>• 识别结果会自动清理掉语音识别的技术标记，只发送纯文本给LLM
            </p>
        </div>
    </div>

    <script>        // 配置参数
        const CONFIG = {
            SAMPLE_RATE: 16000,
            CHANNELS: 1,
            CHUNK_SIZE: 2048,
            VAD_THRESHOLD: 0.15,          // 降低VAD阈值，使其更容易检测到语音
            MIN_SPEECH_FRAMES: 2,          // 较小的语音帧数，更快开始识别
            MAX_SILENCE_FRAMES: 5,         // 大幅减少静音帧数，更快结束识别
            AUDIO_RMS_THRESHOLD: 0.025,    // 更低的音频RMS阈值，提高检测灵敏度
            REAL_TIME_FRAMES: 15,          // 减少实时识别所需的帧数
            TAIL_THRESHOLD_RATIO: 0.4,     // 语音结尾判断的阈值比例，数值应小于1
            SPEECH_PADDING_FRAMES: 2,      // 在语音开始前添加的额外帧数
            END_SPEECH_DELAY_MS: 300,      // 语音结束后的额外延迟时间(毫秒)
        };

        // DOM元素        
        const elements = {
            connectBtn: document.getElementById('connect-btn'),
            disconnectBtn: document.getElementById('disconnect-btn'),
            startBtn: document.getElementById('start-btn'),
            stopBtn: document.getElementById('stop-btn'),
            clearBtn: document.getElementById('clear-btn'),
            transcript: document.getElementById('transcript'),
            connectionStatus: document.getElementById('connection-status'),
            statusText: document.getElementById('status-text'),
            serverInfo: document.getElementById('server-info'),
            userInfo: document.getElementById('userInfo'),
            serverUrl: document.getElementById('server-url'),
            apiKey: document.getElementById('api-key'),
            userToken: document.getElementById('user-token'),  // 添加用户token元素
            llmApiUrl: document.getElementById('llm-api-url'),  // 添加LLM API URL元素
            checkVoiceprint: document.getElementById('check-voiceprint'),
            onlyRegisterUser: document.getElementById('only-register-user'),            identifyUnregistered: document.getElementById('identify-unregistered'),
            voiceIndicator: document.getElementById('voice-indicator'),
            voiceStatus: document.getElementById('voice-status'),
            recordingStatus: document.getElementById('recording-status'),
            audioFormat: document.getElementById('audio-format'),
            // VAD调试面板元素
            vadMeterFill: document.getElementById('vad-meter-fill'),
            vadMeterThreshold: document.getElementById('vad-meter-threshold'),
            vadRms: document.getElementById('vad-rms'),
            vadThreshold: document.getElementById('vad-threshold'),
            vadConfidence: document.getElementById('vad-confidence'),
            vadStatus: document.getElementById('vad-status'),
            audioDuration: document.getElementById('audio-duration')
        };

        // 状态变量
        let socket = null;
        let audioContext = null;
        let mediaStream = null;
        let audioProcessor = null;
        let isRecording = false;
        let isConnected = false;
        let isSpeaking = false;
        let speechFrames = [];
        let silenceFrames = 0;        // 更新状态显示
        function updateStatus(connected) {
            isConnected = connected;
            elements.connectionStatus.classList.toggle('connected', connected);
            elements.statusText.textContent = connected ? '已连接' : '未连接';
            elements.connectBtn.disabled = connected;
            elements.disconnectBtn.disabled = !connected;
            elements.startBtn.disabled = !connected;
            elements.stopBtn.disabled = true;
            
            const serverUrl = elements.serverUrl.value;
            elements.serverInfo.textContent = `服务器: ${serverUrl}`;
            elements.audioFormat.textContent = `音频格式: PCM`;
        }

        // 添加消息到界面
        function addMessage(text, isSystem = false, isError = false) {
            const messageDiv = document.createElement('div');
            messageDiv.classList.add('message');
            
            if (isError) {
                messageDiv.classList.add('error-message');
            } else if (isSystem) {
                messageDiv.classList.add('system-message');
            } else {
                messageDiv.classList.add('user-message');
            }
            
            const timestamp = new Date().toLocaleTimeString();
            messageDiv.textContent = `[${timestamp}] ${text}`;
            
            elements.transcript.appendChild(messageDiv);
            elements.transcript.scrollTop = elements.transcript.scrollHeight;
        }

        // 添加LLM响应到界面
        function addLLMResponse(llmResponse) {
            const responseDiv = document.createElement('div');
            responseDiv.classList.add('message', 'llm-response');
            
            const timestamp = new Date().toLocaleTimeString();
            const headerDiv = document.createElement('div');
            headerDiv.classList.add('llm-response-header');
            headerDiv.textContent = `[${timestamp}] AI助手:`;
            
            const contentDiv = document.createElement('div');
            
            // 处理不同类型的响应
            if (llmResponse.error) {
                contentDiv.innerHTML = `<strong>错误:</strong> ${llmResponse.error}<br>`;
                if (llmResponse.details) {
                    contentDiv.innerHTML += `<em>详情:</em> ${llmResponse.details}`;
                }
                responseDiv.style.backgroundColor = '#f8d7da';
                responseDiv.style.borderLeftColor = '#dc3545';
            } else if (llmResponse.text) {
                // 显示AI响应的文本内容
                contentDiv.textContent = llmResponse.text;
                
                // 如果有token信息，添加到底部
                if (llmResponse.token_info) {
                    const tokenInfoDiv = document.createElement('div');
                    tokenInfoDiv.style.fontSize = '12px';
                    tokenInfoDiv.style.color = '#666';
                    tokenInfoDiv.style.marginTop = '8px';
                    tokenInfoDiv.textContent = `输入tokens: ${llmResponse.token_info.input_tokens}, 输出tokens: ${llmResponse.token_info.output_tokens}`;
                    contentDiv.appendChild(tokenInfoDiv);
                }
            } else {
                // 显示原始响应（作为备用）
                contentDiv.textContent = JSON.stringify(llmResponse, null, 2);
            }
            
            responseDiv.appendChild(headerDiv);
            responseDiv.appendChild(contentDiv);
            
            elements.transcript.appendChild(responseDiv);
            elements.transcript.scrollTop = elements.transcript.scrollHeight;
        }

        // 连接到WebSocket服务器
        function connectToServer() {
            const serverUrl = elements.serverUrl.value;
            if (!serverUrl) {
                addMessage("请输入服务器地址", false, true);
                return;
            }

            try {
                addMessage(`正在连接到 ${serverUrl}...`, true);
                socket = new WebSocket(serverUrl);                socket.onopen = () => {
                    addMessage("WebSocket连接已建立", true);
                    updateStatus(true);
                    // 连接成功后发送初始配置
                    setTimeout(updateServerConfig, 100);
                };

                socket.onmessage = (event) => {
                    try {
                        const response = JSON.parse(event.data);
                        handleServerMessage(response);
                    } catch (error) {
                        console.error("解析服务器消息失败:", error);
                        addMessage(`解析服务器消息失败: ${error.message}`, false, true);
                    }
                };

                socket.onclose = (event) => {
                    addMessage(`WebSocket连接已关闭 (代码: ${event.code})`, true);
                    updateStatus(false);
                    stopRecording();
                };

                socket.onerror = (error) => {
                    addMessage(`WebSocket错误: ${error.message || '未知错误'}`, false, true);
                    updateStatus(false);
                };

            } catch (error) {
                addMessage(`连接错误: ${error.message}`, false, true);
                updateStatus(false);
            }
        }        // 处理服务器消息
        function handleServerMessage(response) {
            console.log("收到服务器响应:", response);
            
            if (response.success) {
                if (response.text) {
                    // 语音识别结果
                    let resultText = response.text;
                    let userInfo = "";
                    
                    // 处理用户信息
                    if (response.user_id) {
                        const userName = response.user_name || response.user_id;
                        userInfo = `[${userName}]`;
                        
                        if (response.similarity) {
                            userInfo += ` (相似度: ${(response.similarity * 100).toFixed(1)}%)`;
                        }
                        
                        // 更新状态栏的用户信息
                        const userInfoElement = document.querySelector('#userInfo');
                        if (userInfoElement) {
                            userInfoElement.textContent = `用户: ${userName}`;
                        }
                    } else {
                        userInfo = "[未识别用户]";
                        const userInfoElement = document.querySelector('#userInfo');
                        if (userInfoElement) {
                            userInfoElement.textContent = "用户: 未识别";
                        }
                    }
                    
                    // 处理语音检测调试信息
                    if (response.speech_detection) {
                        const detection = response.speech_detection;
                        updateVadDebugPanel({
                            rms: detection.rms.value,
                            threshold: detection.rms.threshold,
                            confidence: detection.vad.confidence,
                            hasSpeech: detection.has_speech,
                            audioDuration: detection.audio_stats.duration
                        });
                    }
                    
                    // 显示识别结果
                    addMessage(`${userInfo} ${resultText}`);
                    
                    // 如果有LLM响应，也显示出来
                    if (response.llm_response) {
                        addLLMResponse(response.llm_response);
                    }
                    
                } else if (response.message) {
                    // 系统消息（如配置更新确认）
                    addMessage(response.message, true);
                }
            } else if (response.error) {
                // 错误消息
                addMessage(`错误: ${response.error}`, false, true);
            }
        }// 断开WebSocket连接
        function disconnectFromServer() {
            if (socket) {
                socket.close();
                socket = null;
            }
            stopRecording();
            updateStatus(false);
        }

        // 开始录音
        async function startRecording() {
            if (!isConnected) {
                addMessage("请先连接到服务器", false, true);
                return;
            }

            try {
                // 请求麦克风权限
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: CONFIG.SAMPLE_RATE,
                        channelCount: CONFIG.CHANNELS,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });

                // 创建音频上下文
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: CONFIG.SAMPLE_RATE
                });

                // 创建媒体流源
                const source = audioContext.createMediaStreamSource(mediaStream);

                // 创建录音处理器
                audioProcessor = audioContext.createScriptProcessor(CONFIG.CHUNK_SIZE, CONFIG.CHANNELS, CONFIG.CHANNELS);

                // 连接节点
                source.connect(audioProcessor);
                audioProcessor.connect(audioContext.destination);

                // 设置录音状态
                isRecording = true;
                isSpeaking = false;
                speechFrames = [];
                silenceFrames = 0;
                elements.startBtn.disabled = true;
                elements.stopBtn.disabled = false;

                // 重置语音指示器
                updateVoiceActivityIndicator(false);
                updateRecordingStatus("已开始持续录音，等待语音输入...");

                addMessage("开始录音，请说话...", true);

                // 音频处理回调
                audioProcessor.onaudioprocess = (e) => {
                    if (!isRecording) return;                    // 获取音频数据
                    const inputBuffer = e.inputBuffer;
                    const inputData = inputBuffer.getChannelData(0);

                    // 检测音量 - 使用更加敏感的检测方法
                    const rms = calculateRMS(inputData);
                    
                    // 动态阈值检测：使用当前RMS值和阈值的比较，提高灵敏度
                    const isSpeech = rms > CONFIG.AUDIO_RMS_THRESHOLD;
                    
                    // 更新VAD调试面板
                    updateVadDebugPanel({
                        rms: rms,
                        threshold: CONFIG.AUDIO_RMS_THRESHOLD,
                        isSpeech: isSpeech,
                        audioDuration: inputBuffer.length / CONFIG.SAMPLE_RATE
                    });
                    
                    // 记录RMS值以进行调试
                    if (isSpeaking || rms > CONFIG.AUDIO_RMS_THRESHOLD * 0.7) {
                        console.log(`RMS: ${rms.toFixed(6)}, 阈值: ${CONFIG.AUDIO_RMS_THRESHOLD}, 是语音: ${isSpeech}`);
                    }

                    // 将音频数据转换为Int16
                    const audioData = convertFloat32ToInt16(inputData);                    // VAD状态机逻辑
                    if (isSpeech) {
                        // 检测到语音，保存音频帧
                        speechFrames.push(audioData);
                        
                        // 检测语音开始
                        if (!isSpeaking) {
                            silenceFrames = 0; // 重置静音帧计数
                            
                            // 只需要很少的帧就开始识别
                            if (speechFrames.length >= CONFIG.MIN_SPEECH_FRAMES) {
                                // 在语音开始时，尝试添加之前的几帧来捕获完整的语音开头
                                isSpeaking = true;
                                console.log(`语音开始检测到，当前RMS: ${rms.toFixed(6)}`);
                                updateVoiceActivityIndicator(true);
                                updateRecordingStatus("正在录制语音...");
                                
                                // 语音开始时立即发送一次，加快首次识别速度
                                const initialAudio = concatenateAudioChunks(speechFrames);
                                sendAudioToServer(initialAudio);
                                console.log("语音开始，发送初始语音片段");
                            }
                        } else {
                            // 已经在语音状态，继续重置静音计数
                            silenceFrames = 0;
                        }                        // 实时识别：每积累一定帧数就发送
                        if (isSpeaking && speechFrames.length >= CONFIG.REAL_TIME_FRAMES) {
                            const audioToSend = concatenateAudioChunks(speechFrames);
                            sendAudioToServer(audioToSend);
                            console.log(`持续语音中，发送语音片段进行识别，帧数: ${speechFrames.length}`);
                            
                            // 保留少量重叠帧，保证连续性，但降低延迟
                            speechFrames = speechFrames.slice(-2);
                        }
                    } else {
                        // 静音帧逻辑处理
                        
                        // 如果当前正在说话状态，则处理可能的语音结束
                        if (isSpeaking) {
                            // 增加静音帧计数
                            silenceFrames++;
                            
                            // 收集少量静音帧，以保留自然的语音尾部
                            if (silenceFrames <= CONFIG.SPEECH_PADDING_FRAMES) {
                                speechFrames.push(audioData);
                            }
                              // 当静音帧达到阈值时，判断语音结束
                            if (silenceFrames >= CONFIG.MAX_SILENCE_FRAMES) {
                                // 语音结束，发送最后的音频片段
                                if (speechFrames.length > 0) {
                                    const finalAudio = concatenateAudioChunks(speechFrames);
                                    const finalRms = calculateRMSFromInt16Array(finalAudio);
                                    
                                    // 使用更低的阈值判断是否有效语音，几乎总是发送
                                    if (finalRms > CONFIG.AUDIO_RMS_THRESHOLD * CONFIG.TAIL_THRESHOLD_RATIO) {
                                        sendAudioToServer(finalAudio);
                                        console.log(`检测到语音结束，发送最终语音片段，RMS: ${finalRms.toFixed(6)}, 阈值: ${(CONFIG.AUDIO_RMS_THRESHOLD * CONFIG.TAIL_THRESHOLD_RATIO).toFixed(6)}`);
                                    } else {
                                        console.log(`语音结束但RMS过低，不发送: ${finalRms.toFixed(6)} < ${(CONFIG.AUDIO_RMS_THRESHOLD * CONFIG.TAIL_THRESHOLD_RATIO).toFixed(6)}`);
                                    }
                                }

                                // 重置状态
                                speechFrames = [];
                                isSpeaking = false;
                                updateVoiceActivityIndicator(false);
                                updateRecordingStatus("等待语音输入...");
                            }
                        }
                    }
                };

            } catch (error) {
                addMessage(`录音失败: ${error.message}`, false, true);
                console.error("录音错误:", error);
            }
        }

        // 停止录音
        function stopRecording() {
            isRecording = false;

            if (audioProcessor) {
                audioProcessor.disconnect();
                audioProcessor = null;
            }

            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }

            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }

            // 重置UI状态
            elements.startBtn.disabled = false;
            elements.stopBtn.disabled = true;
            updateVoiceActivityIndicator(false);
            updateRecordingStatus("录音已停止");

            if (isConnected) {
                addMessage("录音已停止", true);
            }
        }        // 发送音频数据到服务器
        async function sendAudioToServer(audioBuffer) {
            if (!socket || socket.readyState !== WebSocket.OPEN) {
                addMessage("未连接到服务器，无法发送音频", false, true);
                return;
            }

            try {
                // 为了降低延迟，直接发送PCM数据，而不转换为WAV格式
                // 转换为Base64
                const base64Audio = arrayBufferToBase64(audioBuffer.buffer);

                // 构建消息 - 适应重构后的WebSocket API格式
                const message = {
                    action: "audio",
                    data: {
                        audio_data: base64Audio,
                        format: "pcm" // 明确指定音频格式为PCM，减少转换延迟
                    }
                };

                // 发送消息
                socket.send(JSON.stringify(message));
                console.log(`已发送PCM音频数据，大小: ${audioBuffer.byteLength} 字节`);

            } catch (error) {
                addMessage(`发送音频错误: ${error.message}`, false, true);
                console.error("发送音频错误:", error);
            }
        }

        // 更新服务器配置
        function updateServerConfig() {
            if (!socket || socket.readyState !== WebSocket.OPEN) {
                return; // 如果未连接则不发送配置
            }

            const userToken = elements.userToken.value.trim();
            console.log("前端：准备发送配置更新，用户token:", userToken ? `${userToken.substring(0, 20)}...` : "无");

            const configMessage = {
                action: "config",
                data: {
                    check_voiceprint: elements.checkVoiceprint.checked,
                    only_register_user: elements.onlyRegisterUser.checked,
                    identify_unregistered: elements.identifyUnregistered.checked,
                    user_token: userToken,  // 添加用户token
                    llm_api_url: elements.llmApiUrl.value.trim()  // 添加LLM API URL
                }
            };

            try {
                socket.send(JSON.stringify(configMessage));
                console.log("前端：已发送配置更新:", configMessage.data);
            } catch (error) {
                addMessage(`配置更新失败: ${error.message}`, false, true);
            }
        }

        // 辅助函数
        function calculateRMS(buffer) {
            let sum = 0;
            for (let i = 0; i < buffer.length; i++) {
                sum += buffer[i] * buffer[i];
            }
            return Math.sqrt(sum / buffer.length);
        }

        function calculateRMSFromInt16Array(int16Array) {
            let sum = 0;
            for (let i = 0; i < int16Array.length; i++) {
                const normalized = int16Array[i] / 32768.0;
                sum += normalized * normalized;
            }
            return Math.sqrt(sum / int16Array.length);
        }

        function convertFloat32ToInt16(buffer) {
            const int16Array = new Int16Array(buffer.length);
            for (let i = 0; i < buffer.length; i++) {
                int16Array[i] = Math.max(-32768, Math.min(32767, buffer[i] * 32768));
            }
            return int16Array;
        }

        function concatenateAudioChunks(chunks) {
            const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
            const result = new Int16Array(totalLength);
            let offset = 0;
            for (const chunk of chunks) {
                result.set(chunk, offset);
                offset += chunk.length;
            }
            return result;
        }

        function arrayBufferToBase64(buffer) {
            const binary = String.fromCharCode.apply(null, new Uint8Array(buffer));
            return btoa(binary);
        }        // 将PCM数据转换为WAV格式
        function convertToWav(pcmData) {
            // WAV文件头参数
            const numChannels = CONFIG.CHANNELS;
            const sampleRate = CONFIG.SAMPLE_RATE;
            const bitsPerSample = 16; // Int16 = 16位
            const bytesPerSample = bitsPerSample / 8;
            const blockAlign = numChannels * bytesPerSample;
            const byteRate = sampleRate * blockAlign;
            const dataSize = pcmData.length * bytesPerSample;
            const buffer = new ArrayBuffer(44 + dataSize);
            const view = new DataView(buffer);

            // 写入WAV文件头 - 注意这里使用标准WAV格式
            // "RIFF"标识 - 必须是大写
            writeString(view, 0, 'RIFF');
            // 文件大小 (文件总字节数 - 8) - 使用小端字节序 (第5个参数为true)
            view.setUint32(4, 36 + dataSize, true);
            // "WAVE"格式 - 必须是大写
            writeString(view, 8, 'WAVE');
            // "fmt "子块标识 (注意fmt后有一个空格)
            writeString(view, 12, 'fmt ');
            // 子块大小 (固定为16表示PCM格式)
            view.setUint32(16, 16, true);
            // 音频格式 (1 表示 PCM)
            view.setUint16(20, 1, true);
            // 通道数
            view.setUint16(22, numChannels, true);
            // 采样率
            view.setUint32(24, sampleRate, true);
            // 字节率 (= 采样率 * 通道数 * 每个样本的字节数)
            view.setUint32(28, byteRate, true);
            // 块对齐 (= 通道数 * 每个样本的字节数)
            view.setUint16(32, blockAlign, true);
            // 采样位数
            view.setUint16(34, bitsPerSample, true);
            // "data"子块标识
            writeString(view, 36, 'data');
            // 数据大小 (= 采样数 * 通道数 * 每个样本的字节数)
            view.setUint32(40, dataSize, true);

            // 写入PCM数据 - 注意这里使用小端字节序 (第3个参数为true)
            const pcmOffset = 44;
            for (let i = 0; i < pcmData.length; i++) {
                view.setInt16(pcmOffset + (i * bytesPerSample), pcmData[i], true);
            }

            return buffer;
        }

        // 辅助函数：将字符串写入DataView
        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }        function updateVoiceActivityIndicator(isActive) {
            if (isActive) {
                elements.voiceIndicator.classList.add('active');
                elements.voiceStatus.textContent = '检测到语音 (正在识别)';
            } else {
                elements.voiceIndicator.classList.remove('active');
                elements.voiceStatus.textContent = '等待语音输入';
            }
        }

        function updateRecordingStatus(status) {
            if (elements.recordingStatus) {
                elements.recordingStatus.textContent = status;
            }
        }

        function clearTranscript() {
            elements.transcript.innerHTML = '';
            addMessage("记录已清空", true);
        }        // 初始化事件监听
        function initEventListeners() {
            elements.connectBtn.addEventListener('click', connectToServer);
            elements.disconnectBtn.addEventListener('click', disconnectFromServer);
            elements.startBtn.addEventListener('click', startRecording);
            elements.stopBtn.addEventListener('click', stopRecording);
            elements.clearBtn.addEventListener('click', clearTranscript);

            // 配置变更监听器
            elements.checkVoiceprint.addEventListener('change', updateServerConfig);
            elements.onlyRegisterUser.addEventListener('change', updateServerConfig);
            elements.identifyUnregistered.addEventListener('change', updateServerConfig);
            elements.userToken.addEventListener('input', updateServerConfig);  // 使用input事件，实时更新token
            elements.llmApiUrl.addEventListener('input', updateServerConfig);  // 使用input事件，实时更新LLM API URL

            // 页面关闭前清理资源
            window.addEventListener('beforeunload', () => {
                stopRecording();
                disconnectFromServer();
            });
        }

        // 检查浏览器兼容性
        function checkBrowserCompatibility() {
            if (!window.WebSocket) {
                addMessage("错误: 您的浏览器不支持WebSocket，请使用现代浏览器", false, true);
                elements.connectBtn.disabled = true;
            }

            if (!window.AudioContext && !window.webkitAudioContext) {
                addMessage("错误: 您的浏览器不支持AudioContext，无法录制音频", false, true);
                elements.startBtn.disabled = true;
            }

            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                addMessage("错误: 您的浏览器不支持音频捕获，请使用现代浏览器并确保使用HTTPS或localhost", false, true);
                elements.startBtn.disabled = true;
            }
        }        // 更新VAD调试面板
        function updateVadDebugPanel(data) {
            try {
                // 确保元素存在
                if (!elements.vadMeterFill || !elements.vadMeterThreshold || 
                    !elements.vadRms || !elements.vadThreshold || 
                    !elements.vadConfidence || !elements.vadStatus || 
                    !elements.audioDuration) {
                    console.warn("VAD调试面板元素不存在");
                    return;
                }
                
                // 更新RMS能量显示
                if (data.rms !== undefined) {
                    const rmsValue = data.rms;
                    const maxRmsValue = Math.max(0.1, data.threshold * 4); // 动态调整最大值
                    const rmsPercent = Math.min(100, (rmsValue / maxRmsValue) * 100);
                    
                    // 更新能量条
                    elements.vadMeterFill.style.width = `${rmsPercent}%`;
                    
                    // 判断是否有语音 (优先使用hasSpeech，否则使用isSpeech)
                    const isSpeechDetected = data.hasSpeech !== undefined ? data.hasSpeech : data.isSpeech;
                    elements.vadMeterFill.style.backgroundColor = isSpeechDetected ? '#2ecc71' : '#3498db';
                    
                    // 更新阈值线位置
                    const thresholdPercent = Math.min(100, (data.threshold / maxRmsValue) * 100);
                    elements.vadMeterThreshold.style.left = `${thresholdPercent}%`;
                    
                    // 更新数值显示
                    elements.vadRms.textContent = rmsValue.toFixed(4);
                    elements.vadThreshold.textContent = data.threshold.toFixed(4);
                }
                
                // 更新VAD置信度
                if (data.confidence !== undefined) {
                    elements.vadConfidence.textContent = (data.confidence * 100).toFixed(1) + '%';
                }
                
                // 更新语音状态
                const isSpeechDetected = data.hasSpeech !== undefined ? data.hasSpeech : data.isSpeech;
                if (isSpeechDetected !== undefined) {
                    elements.vadStatus.textContent = isSpeechDetected ? '检测到语音' : '静音';
                    elements.vadStatus.style.color = isSpeechDetected ? '#2ecc71' : '#7f8c8d';
                }
                
                // 更新音频时长
                if (data.audioDuration !== undefined) {
                    elements.audioDuration.textContent = data.audioDuration.toFixed(2) + 's';
                }
            } catch (error) {
                console.error("更新VAD调试面板出错:", error);
            }
        }

        // 初始化应用
        function init() {
            updateStatus(false);
            initEventListeners();
            addMessage("欢迎使用VOXELINK实时语音识别系统", true);
            addMessage("请点击\"连接服务器\"按钮开始", true);
            checkBrowserCompatibility();
        }

        // 启动应用
        document.addEventListener('DOMContentLoaded', function() {
            init();
        });
    </script>
</body>
</html>
